version: '3.8'

# Toàn bộ service nằm chung trên 1 mạng để chúng gọi nhau qua hostname.
networks:
  data-net:
    driver: bridge

# ===================================================================
# THÊM VOLUMES (KHÔNG SỬA CODE GỐC)
# ===================================================================
volumes:
  minio_data:       # Lưu object thực tế cho MinIO (S3 backend)
  kafka_1_data:     # Lưu log segment + metadata cho broker 1
  kafka_2_data:     # Lưu log segment + metadata cho broker 2
  airflow_data:     # Airflow DB + cấu trúc workspace nếu cần
# ===================================================================

services:

  # ================================================================
  # 1) KAFKA CLUSTER — 2 BROKERS (KRaft mode, không cần ZooKeeper)
  # ================================================================
  kafka-1:
    image: confluentinc/cp-kafka:7.6.0
    container_name: kafka-1
    environment:
      # ID của node trong cluster (mỗi broker khác nhau)
      KAFKA_NODE_ID: 1

      # KRaft mode — 1 node vừa làm broker vừa làm controller
      KAFKA_PROCESS_ROLES: broker,controller

      # Danh sách controller voters (ID@HOST:PORT) — cả 2 node cùng vote
      # FIX: Đảm bảo node 2 dùng port 29094 cho controller để không trùng port external
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka-1:29093,2@kafka-2:29094

      # Listener nội bộ (PLAINTEXT) và listener cho controller (quorum)
      # CŨ — nhưng KHÔNG XOÁ
      # KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:29093

      # THAY THẾ ĐÚNG — GIỮ LẠI DÒNG CŨ, THÊM DÒNG MỚI ĐÚNG NGHĨA
      # INTERNAL (docker) / EXTERNAL (host) / CONTROLLER (KRaft)
      KAFKA_LISTENERS: INTERNAL://:9092,EXTERNAL://:29092,CONTROLLER://:29093
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-1:9092,EXTERNAL://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL

      # Map loại listener → giao thức
      # CŨ — giữ nguyên (KHÔNG XÓA)
      # KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT

      # Tên listener dành riêng cho controller role
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER

      # Cluster ID cố định — phải giống nhau trên tất cả brokers
      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk

      # Hệ số replication cho internal topics
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2

      # Auto-create topic khi producer gửi message lần đầu
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"

    ports:
      - "9092:9092"     # INTERNAL → container
      - "29092:29092"   # EXTERNAL → host (Python, Spark ngoài docker)
      # KHÔNG EXPOSE CONTROLLER

    networks:
      - data-net
    mem_limit: 1024m
    volumes:
      - kafka_1_data:/var/lib/kafka/data

  kafka-2:
    image: confluentinc/cp-kafka:7.6.0
    container_name: kafka-2
    environment:

      # Dual listeners cho broker 2
      # FIX: Đổi CONTROLLER sang 29094 để không trùng với EXTERNAL 29093
      KAFKA_LISTENERS: INTERNAL://:9092,EXTERNAL://:29093,CONTROLLER://:29094
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-2:9092,EXTERNAL://localhost:29093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL

      # Các dòng cũ — GIỮ NGUYÊN
      KAFKA_NODE_ID: 2
      KAFKA_PROCESS_ROLES: broker,controller
      # FIX: Update port voters khớp với listener controller mới (29094)
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka-1:29093,2@kafka-2:29094
      # KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:29093
      # KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-2:9092
      # KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"

    ports:
      - "9093:9092"    # internal port map
      - "29093:29093"  # external port host dùng

    networks:
      - data-net
    mem_limit: 1024m
    # -----------------------------------
    # THÊM VOLUME LƯU DỮ LIỆU BROKER 2
    # -----------------------------------
    volumes:
      - kafka_2_data:/var/lib/kafka/data


  # Kafka UI để xem topic / consumer / offset
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8085:8080"   # mở UI tại http://localhost:8085
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      # Bootstraps servers gồm 2 brokers
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka-1:9092,kafka-2:9092
    depends_on:
      - kafka-1
      - kafka-2
    networks:
      - data-net


  # ================================================================
  # 2) MINIO — Object Storage tương thích S3
  # ================================================================
  minio:
    image: minio/minio:latest
    container_name: minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: password123
    ports:
      - "9000:9000"  # API S3
      - "9001:9001"  # Console UI
    networks:
      - data-net
    mem_limit: 256m
    # -----------------------------------
    # THÊM VOLUME CHO MINIO
    # -----------------------------------
    volumes:
      - minio_data:/data


  # ================================================================
  # 3) SPARK CLUSTER — 1 MASTER + 2 WORKERS
  # ================================================================
  spark-master:
    # build: ./docker/spark
    image: apache/spark:3.5.1
    user: root # thêm vào để pip install lúc vào container của spark

    container_name: spark-master
    command: >
      bash -c "/opt/spark/sbin/start-master.sh && tail -f /dev/null"
    ports:
      - "8080:8080"  # Spark Web UI
      - "7077:7077"  # Spark master RPC
    volumes:
      - ./app:/opt/workspace/app
    networks:
      - data-net
    mem_limit: 2048m


  spark-worker-1:
    # build: ./docker/spark
    image: apache/spark:3.5.1
    user: root # thêm vào để pip install lúc vào container của spark
    container_name: spark-worker-1
    depends_on:
      - spark-master
    command: >
      bash -c "/opt/spark/sbin/start-worker.sh spark://spark-master:7077 && tail -f /dev/null"
    environment:
      SPARK_WORKER_MEMORY: "1G" # RAM Spark được phép dùng
    volumes:
      - ./app:/opt/workspace/app
    networks:
      - data-net
    mem_limit: 2048m


  spark-worker-2:
    # build: ./docker/spark
    image: apache/spark:3.5.1
    user: root # thêm vào để pip install lúc vào container của spark

    container_name: spark-worker-2
    depends_on:
      - spark-master
    command: >
      bash -c "/opt/spark/sbin/start-worker.sh spark://spark-master:7077 && tail -f /dev/null"
    environment:
      SPARK_WORKER_MEMORY: "1G"
    volumes:
      - ./app:/opt/workspace/app
    networks:
      - data-net
    mem_limit: 2048m


  # ================================================================
  # 4) AIRFLOW — chạy bằng SQLite (dev mode)
  # ================================================================
  airflow:
    build: ./docker/airflow
    image: airflow-custom
    container_name: airflow
    command: standalone
    environment:
      AIRFLOW__CORE__EXECUTOR: SequentialExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: sqlite:////opt/airflow/airflow.db
      _AIRFLOW_WWW_USER_CREATE: "true"
      _AIRFLOW_WWW_USER_USERNAME: "admin"
      _AIRFLOW_WWW_USER_PASSWORD: "admin"
    ports:
      - "8081:8080"  # UI: http://localhost:8081
    volumes:
      - ./airflow:/opt/airflow
      - ./app:/opt/workspace/app
    networks:
      - data-net
    mem_limit: 1500m
